{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbuNtXSJ-PHa"
      },
      "source": [
        "# Part 0 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6QzguX_Zr9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29ba5b3f-59e5-4ded-e405-865df92e7587"
      },
      "source": [
        "#Importing the Keras Libraries and Packages\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjcQgqtH6NVQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ae51bdd8-cc15-40c5-ee37-c7ca7b3d1655"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydatdQe_7jGS"
      },
      "source": [
        "Preprocessing the Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgbq97sE7lBw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "82b891b8-5888-4af5-c761-0162950a6353"
      },
      "source": [
        "#we got the following code from keras api https://keras.io/api/preprocessing/image/\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "#we're just performing augmentations to the image such as flipping and shearing so that we can train better on our training set\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        'training_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "#target size is just the final image size, so we picked 64x64 pixels cuz it makes the training not that long\n",
        "#classmode is binary cuz its either dog or cat, but categorical is the other option if we have more\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzMBdbPM8_GQ"
      },
      "source": [
        "Preprocessing the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y1oEpO29Aun",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4f54db0c-a276-4172-e386-690b35ae1cb4"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255) #so we don't perform the shearing and flipping and zooming on the test set, cuz we're not training with it. We just feed it into our model as is, but we are rescaling as we must do with a normal ANN, cuz we feature scaled it\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'test_set',\n",
        "        target_size=(64,64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xd9CjPgHjW_"
      },
      "source": [
        "# Part 1 - Building the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG1HuB2ZIDkW"
      },
      "source": [
        "#Initializing the CNN\n",
        "classifier = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMVVTF70LxG9"
      },
      "source": [
        "### 1.1 Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X3ubSKgL2b2"
      },
      "source": [
        "classifier.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, input_shape = (64,64,3), activation = 'relu')) #we chose 32 feature detectors (filters), meaning we'll create 32 layers of feature maps. 32 is the standard default value to go with, so we just doubled it. Our feature detector matrix will have a size (kernel) size of 3x3\n",
        "#the input_shape is saying we have 3 channels because we have a coloured image (it'd be 1 for a bw image), and 64,64 are the dimensions of the 2D array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doRFN79PPjBd"
      },
      "source": [
        "###1.2 Max Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H8K5yMjPkR2"
      },
      "source": [
        "classifier.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides = 2))\n",
        "#we picked 2x2 as our max pooling feature map, and it will pick the maximum value for each 2x2 pool every 2 strides. This ultimately reduced the size, making our model easier to process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU9GdcKcvfwk"
      },
      "source": [
        "###1.2.1 Adding a Second Convolutional Layer to Improve Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHLl_I5AvnKJ"
      },
      "source": [
        "classifier.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu')) #we chose 64 feature detectors, meaning we'll create 64 layers of feature maps. We doubled it from previous because it'll help get an even more accurate result. Our feature detector matrix will have a size (kernel) size of 3x3\n",
        "#Didn't near the input shape above cuz we already did it the first time\n",
        "classifier.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides = 2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnBAoQNGRrDM"
      },
      "source": [
        "###1.3 Flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxMQ8Oq9Rx1F"
      },
      "source": [
        "classifier.add(tf.keras.layers.Flatten())\n",
        "#Now we vectorize the Max Pooling Feature Map, to get a spacial properties/structure of the pixels and then we can add that into our ANN as numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LkzzuehS0D0"
      },
      "source": [
        "###1.4 Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl-uqhoHSmLF"
      },
      "source": [
        "classifier.add(tf.keras.layers.Dense(units = 128, activation = 'relu')) #we have 128 determined by experiments and to select a power of 2\n",
        "classifier.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "classifier.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid')) #we have 1 cuz we only have 1 overall output prediction, and sigmoid is for binary outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQYdn3tuUVyl"
      },
      "source": [
        "###1.5 Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HtNkoOMT-Mu"
      },
      "source": [
        "classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy']) #so here we're not using mse as the loss cuz its a binary classification\n",
        "#use loss = categorical_crossentropy if we have more than 2 outcomes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ1_nMirVBqJ"
      },
      "source": [
        "# Part 2 - Fitting the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuRRotkOGnnE"
      },
      "source": [
        "Adding a Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nTXaxiR1XJF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3d80336f-daeb-4a03-a446-5bdb2a382be6"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"classifier_CatOrDog_1CP.h5\", monitor='loss', verbose=1, save_best_only=True, mode='auto', period=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\nclassifier.fit(\\n        training_set,\\n        steps_per_epoch=8000,\\n        epochs=25,\\n        validation_data=test_set,\\n        validation_steps=2000,\\n        verbose=1)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgKcK99iGqRb"
      },
      "source": [
        "Adding Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFj975VgGtr5"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 25) #here our mode is min, because we're trying to minimize the loss. if our metric was accuracy, we'd use max instead as the mode. patience = 5 means we wait 5 epochs until it stops \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD9KQWyTRvW1"
      },
      "source": [
        "classifier.fit(\n",
        "        x = training_set,\n",
        "        steps_per_epoch=8000/32,\n",
        "        epochs=100,\n",
        "        validation_data=test_set,\n",
        "        validation_steps = 2000/32,\n",
        "        callbacks=[checkpoint, es])\n",
        "#32 is the batch size\n",
        "\n",
        "classifier.save_weights('CatorDog_CNN.h5')\n",
        "classifier.save('CatorDog_CNN.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3zU-Qz_2j4J"
      },
      "source": [
        "# Part 3 - Making New Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ts9Vv8N1gBJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a0b838e6-1ffc-439b-81be-b0726fcacf7d"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image \n",
        "\n",
        "test_image = image.load_img('/d1.jpg', target_size=(64, 64)) #making our image 64,64 to fit into our model\n",
        "\n",
        "test_image = image.img_to_array(test_image) #adding the 3 dimension later\n",
        "test_image = np.expand_dims(test_image, axis = 0) #adding the 4th dimension for what the predict method expects\n",
        "result = classifier.predict(test_image)\n",
        "\n",
        "if result[0][0]==1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'\n",
        "  \n",
        "\n",
        "print(training_set.class_indices)\n",
        "print(prediction, result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'cats': 0, 'dogs': 1}\n",
            "dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doLUbpLGCAGD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}